{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf01f6f-6a6d-4b2b-9282-24c1c366b6c4",
   "metadata": {},
   "source": [
    "### `Data Preprocessing`\n",
    "This jupyter notebook contains data set cleaning, tokenization and extracting embeddings (sentence vectors) for a suicidal tweet classifier.\n",
    "\n",
    "I tried to explain the important parts as much as I can.\n",
    "\n",
    "For the tokenization and embedding parts, I used the [BERT](https://huggingface.co/docs/transformers/model_doc/bert) model (specifically `bert-base-uncased` model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8644043-1c67-490f-8c63-38290d752d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emirbalci/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import contractions\n",
    "import emoji\n",
    "\n",
    "import torch\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc74b21-8eda-4e01-9248-a9b3dc982881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vader_sentiment_label</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2699</td>\n",
       "      <td>Wow, my dad yday: “you don’t take those stupid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5995</td>\n",
       "      <td>what part of this was really harmfult of a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>one of the ways I got through my #depression i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8643</td>\n",
       "      <td>see i wanna do one of them but they all say th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>IS IT clinical depression or is it the palpabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  vader_sentiment_label  vader_score  \\\n",
       "0           0                      0      -0.2699   \n",
       "1           1                      0      -0.5995   \n",
       "2           2                      1       0.3382   \n",
       "3           3                      0      -0.8643   \n",
       "4           4                      0      -0.8316   \n",
       "\n",
       "                                               tweet  \n",
       "0  Wow, my dad yday: “you don’t take those stupid...  \n",
       "1  what part of this was really harmfult of a lot...  \n",
       "2  one of the ways I got through my #depression i...  \n",
       "3  see i wanna do one of them but they all say th...  \n",
       "4  IS IT clinical depression or is it the palpabl...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/vader_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e777bc-2755-48a9-8e55-9fde455869f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22963 entries, 0 to 22962\n",
      "Data columns (total 3 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   vader_sentiment_label  22963 non-null  int64  \n",
      " 1   vader_score            22963 non-null  float64\n",
      " 2   tweet                  22963 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 538.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e8161-1a11-4bde-9882-664a49026e62",
   "metadata": {},
   "source": [
    "### Couple of things I noticed after the examination of the trimmed data:\n",
    "1) Most of the tweets contain hashtags, emojis, numbers, and symbols.\n",
    "2) The overall emotion of the tweet depends on what kind of emoji(s) does it contains. For example, the tweet that contains '😞' emoji is more likely to be depressive.\n",
    "3) Some of the punctiation marks are repetitive (i.e. '!!' or '??'). These marks could be valuable.\n",
    "4) There are non-English tweets.\n",
    "5) Most of the tweets contain tagged users (i.e. '@elon'). A column named 'mentions' in the original copy of the dataset provides the tagged users in the tweet however, not all of them appear in the column.\n",
    "6) Some of the tweets contain links and hardcoded pictures (i.e. 'pic.twitter.com/tBhxLdatP8'). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa538ef-9cde-4d70-97b1-b9247bcfac0b",
   "metadata": {},
   "source": [
    "### Some valuable attributes will be saved for later use:\n",
    "#### These attributes represent tweet's characteristic features. \n",
    "- Swearing or offensive word(s) [Integer] => How many are there?\n",
    "- Tweet length [Integer] => this column will be calculated after removing links.\n",
    "- Emoji attribute will be break down into two columns: pos_emoji [Boolean], neg_emoji [Boolean]\n",
    "- URL/Link [Boolean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5642d-80b9-4f77-8715-42598ae9ec86",
   "metadata": {},
   "source": [
    "### Tweets that contain depressive emojis are more likely to be depressive tweets.\n",
    "- So, all of the emojis in the dataset must be gathered into a data structure for later analysis.\n",
    "- Then, most common emojis must be found for categorization.\n",
    "- Finally, tweets should be checked whether they contain a categorized emoji or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199a64c9-c8cb-4317-bbd9-5fc5c9da204c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('😂', [':face_with_tears_of_joy:', 460]),\n",
       " ('😭', [':loudly_crying_face:', 342]),\n",
       " ('❤', [':red_heart:', 272]),\n",
       " ('💔', [':broken_heart:', 175]),\n",
       " ('😔', [':pensive_face:', 132]),\n",
       " ('🏻', [':light_skin_tone:', 127]),\n",
       " ('🤣', [':rolling_on_the_floor_laughing:', 125]),\n",
       " ('♀', [':female_sign:', 113]),\n",
       " ('🙏', [':folded_hands:', 107]),\n",
       " ('🏼', [':medium-light_skin_tone:', 105]),\n",
       " ('😍', [':smiling_face_with_heart-eyes:', 102]),\n",
       " ('💜', [':purple_heart:', 95]),\n",
       " ('🏾', [':medium-dark_skin_tone:', 91]),\n",
       " ('🙃', [':upside-down_face:', 88]),\n",
       " ('🏽', [':medium_skin_tone:', 88]),\n",
       " ('🤷', [':person_shrugging:', 87]),\n",
       " ('😊', [':smiling_face_with_smiling_eyes:', 76]),\n",
       " ('😩', [':weary_face:', 74]),\n",
       " ('🙄', [':face_with_rolling_eyes:', 72]),\n",
       " ('💕', [':two_hearts:', 71]),\n",
       " ('😢', [':crying_face:', 69]),\n",
       " ('♂', [':male_sign:', 68]),\n",
       " ('🤔', [':thinking_face:', 63]),\n",
       " ('🥺', [':pleading_face:', 61]),\n",
       " ('😞', [':disappointed_face:', 60]),\n",
       " ('💯', [':hundred_points:', 59]),\n",
       " ('🖤', [':black_heart:', 57]),\n",
       " ('🤦', [':person_facepalming:', 52]),\n",
       " ('👏', [':clapping_hands:', 52]),\n",
       " ('👍', [':thumbs_up:', 51]),\n",
       " ('🤗', [':smiling_face_with_open_hands:', 44]),\n",
       " ('✌', [':victory_hand:', 43]),\n",
       " ('🔥', [':fire:', 43]),\n",
       " ('🤪', [':zany_face:', 42]),\n",
       " ('☺', [':smiling_face:', 41]),\n",
       " ('😅', [':grinning_face_with_sweat:', 41]),\n",
       " ('✨', [':sparkles:', 41]),\n",
       " ('😪', [':sleepy_face:', 38]),\n",
       " ('😌', [':relieved_face:', 38]),\n",
       " ('💚', [':green_heart:', 37]),\n",
       " ('😎', [':smiling_face_with_sunglasses:', 36]),\n",
       " ('😒', [':unamused_face:', 35]),\n",
       " ('💙', [':blue_heart:', 35]),\n",
       " ('😳', [':flushed_face:', 33]),\n",
       " ('👌', [':OK_hand:', 33]),\n",
       " ('🙌', [':raising_hands:', 31]),\n",
       " ('🥴', [':woozy_face:', 31]),\n",
       " ('🥰', [':smiling_face_with_hearts:', 31]),\n",
       " ('♥', [':heart_suit:', 31]),\n",
       " ('😁', [':beaming_face_with_smiling_eyes:', 31]),\n",
       " ('💖', [':sparkling_heart:', 30]),\n",
       " ('💪', [':flexed_biceps:', 30]),\n",
       " ('💀', [':skull:', 29]),\n",
       " ('😘', [':face_blowing_a_kiss:', 29]),\n",
       " ('⚡', [':high_voltage:', 28]),\n",
       " ('🙂', [':slightly_smiling_face:', 26]),\n",
       " ('‼', [':double_exclamation_mark:', 25]),\n",
       " ('🤧', [':sneezing_face:', 25]),\n",
       " ('😫', [':tired_face:', 25]),\n",
       " ('😣', [':persevering_face:', 25]),\n",
       " ('🌸', [':cherry_blossom:', 23]),\n",
       " ('✅', [':check_mark_button:', 23]),\n",
       " ('🌈', [':rainbow:', 23]),\n",
       " ('👊', [':oncoming_fist:', 22]),\n",
       " ('✈', [':airplane:', 22]),\n",
       " ('😱', [':face_screaming_in_fear:', 22]),\n",
       " ('➡', [':right_arrow:', 21]),\n",
       " ('😕', [':confused_face:', 21]),\n",
       " ('💗', [':growing_heart:', 20]),\n",
       " ('😥', [':sad_but_relieved_face:', 20]),\n",
       " ('™', [':trade_mark:', 20]),\n",
       " ('🤡', [':clown_face:', 20]),\n",
       " ('😇', [':smiling_face_with_halo:', 19]),\n",
       " ('👇', [':backhand_index_pointing_down:', 19]),\n",
       " ('🗣', [':speaking_head:', 19]),\n",
       " ('🎶', [':musical_notes:', 18]),\n",
       " ('😐', [':neutral_face:', 18]),\n",
       " ('🤙', [':call_me_hand:', 17]),\n",
       " ('☹', [':frowning_face:', 17]),\n",
       " ('😓', [':downcast_face_with_sweat:', 17]),\n",
       " ('🌚', [':new_moon_face:', 17]),\n",
       " ('💞', [':revolving_hearts:', 16]),\n",
       " ('👁', [':eye:', 16]),\n",
       " ('💛', [':yellow_heart:', 16]),\n",
       " ('💓', [':beating_heart:', 16]),\n",
       " ('👀', [':eyes:', 16]),\n",
       " ('⭐', [':star:', 16]),\n",
       " ('😉', [':winking_face:', 15]),\n",
       " ('😴', [':sleeping_face:', 15]),\n",
       " ('😤', [':face_with_steam_from_nose:', 15]),\n",
       " ('👋', [':waving_hand:', 15]),\n",
       " ('🤝', [':handshake:', 14]),\n",
       " ('🤩', [':star-struck:', 14]),\n",
       " ('😑', [':expressionless_face:', 14]),\n",
       " ('😖', [':confounded_face:', 14]),\n",
       " ('🤯', [':exploding_head:', 14]),\n",
       " ('✔', [':check_mark:', 14]),\n",
       " ('🤘', [':sign_of_the_horns:', 13]),\n",
       " ('😝', [':squinting_face_with_tongue:', 13]),\n",
       " ('✊', [':raised_fist:', 13]),\n",
       " ('😬', [':grimacing_face:', 13]),\n",
       " ('⚽', [':soccer_ball:', 13]),\n",
       " ('😀', [':grinning_face:', 13]),\n",
       " ('🥵', [':hot_face:', 13]),\n",
       " ('👉', [':backhand_index_pointing_right:', 13]),\n",
       " ('🙁', [':slightly_frowning_face:', 12]),\n",
       " ('🤭', [':face_with_hand_over_mouth:', 12]),\n",
       " ('😏', [':smirking_face:', 12]),\n",
       " ('🏿', [':dark_skin_tone:', 11]),\n",
       " ('⬇', [':down_arrow:', 11]),\n",
       " ('🎵', [':musical_note:', 11]),\n",
       " ('🧡', [':orange_heart:', 11]),\n",
       " ('❣', [':heart_exclamation:', 11]),\n",
       " ('🙅', [':person_gesturing_NO:', 11]),\n",
       " ('😡', [':enraged_face:', 11]),\n",
       " ('🌿', [':herb:', 10]),\n",
       " ('🙋', [':person_raising_hand:', 10]),\n",
       " ('👅', [':tongue:', 10]),\n",
       " ('😄', [':grinning_face_with_smiling_eyes:', 10]),\n",
       " ('🤟', [':love-you_gesture:', 9]),\n",
       " ('😜', [':winking_face_with_tongue:', 9]),\n",
       " ('⚠', [':warning:', 9]),\n",
       " ('💡', [':light_bulb:', 9]),\n",
       " ('🙈', [':see-no-evil_monkey:', 9]),\n",
       " ('💘', [':heart_with_arrow:', 9]),\n",
       " ('😆', [':grinning_squinting_face:', 9]),\n",
       " ('🧠', [':brain:', 8]),\n",
       " ('💅', [':nail_polish:', 8]),\n",
       " ('✋', [':raised_hand:', 8]),\n",
       " ('🧐', [':face_with_monocle:', 8]),\n",
       " ('🤠', [':cowboy_hat_face:', 8]),\n",
       " ('🎉', [':party_popper:', 8]),\n",
       " ('💁', [':person_tipping_hand:', 8]),\n",
       " ('😷', [':face_with_medical_mask:', 8]),\n",
       " ('◾', [':black_medium-small_square:', 8]),\n",
       " ('💥', [':collision:', 7]),\n",
       " ('💆', [':person_getting_massage:', 7]),\n",
       " ('🌟', [':glowing_star:', 7]),\n",
       " ('🤚', [':raised_back_of_hand:', 7]),\n",
       " ('😠', [':angry_face:', 7]),\n",
       " ('💊', [':pill:', 7]),\n",
       " ('🤞', [':crossed_fingers:', 7]),\n",
       " ('🤬', [':face_with_symbols_on_mouth:', 7]),\n",
       " ('☕', [':hot_beverage:', 7]),\n",
       " ('😟', [':worried_face:', 7]),\n",
       " ('🤑', [':money-mouth_face:', 7]),\n",
       " ('🚫', [':prohibited:', 7]),\n",
       " ('👩', [':woman:', 7]),\n",
       " ('🤕', [':face_with_head-bandage:', 7]),\n",
       " ('🤒', [':face_with_thermometer:', 7]),\n",
       " ('🍃', [':leaf_fluttering_in_wind:', 7]),\n",
       " ('🗿', [':moai:', 7]),\n",
       " ('💤', [':ZZZ:', 7]),\n",
       " ('👎', [':thumbs_down:', 6]),\n",
       " ('🤮', [':face_vomiting:', 6]),\n",
       " ('💝', [':heart_with_ribbon:', 6]),\n",
       " ('💋', [':kiss_mark:', 6]),\n",
       " ('🤖', [':robot:', 6]),\n",
       " ('😶', [':face_without_mouth:', 6]),\n",
       " ('😵', [':face_with_crossed-out_eyes:', 6]),\n",
       " ('🚀', [':rocket:', 6]),\n",
       " ('🤸', [':person_cartwheeling:', 6]),\n",
       " ('⚪', [':white_circle:', 6]),\n",
       " ('😃', [':grinning_face_with_big_eyes:', 5]),\n",
       " ('😹', [':cat_with_tears_of_joy:', 5]),\n",
       " ('🥀', [':wilted_flower:', 5]),\n",
       " ('🦋', [':butterfly:', 5]),\n",
       " ('🌱', [':seedling:', 5]),\n",
       " ('💻', [':laptop:', 5]),\n",
       " ('🤓', [':nerd_face:', 5]),\n",
       " ('😰', [':anxious_face_with_sweat:', 5]),\n",
       " ('💫', [':dizzy:', 5]),\n",
       " ('💦', [':sweat_droplets:', 5]),\n",
       " ('🤨', [':face_with_raised_eyebrow:', 5]),\n",
       " ('😯', [':hushed_face:', 5]),\n",
       " ('🚨', [':police_car_light:', 4]),\n",
       " ('⤵', [':right_arrow_curving_down:', 4]),\n",
       " ('😈', [':smiling_face_with_horns:', 4]),\n",
       " ('❓', [':red_question_mark:', 4]),\n",
       " ('☀', [':sun:', 4]),\n",
       " ('💃', [':woman_dancing:', 4]),\n",
       " ('💭', [':thought_balloon:', 4]),\n",
       " ('☝', [':index_pointing_up:', 4]),\n",
       " ('📞', [':telephone_receiver:', 4]),\n",
       " ('👿', [':angry_face_with_horns:', 4]),\n",
       " ('😛', [':face_with_tongue:', 4]),\n",
       " ('😨', [':fearful_face:', 4]),\n",
       " ('📷', [':camera:', 4]),\n",
       " ('🌻', [':sunflower:', 4]),\n",
       " ('🦡', [':badger:', 4]),\n",
       " ('🙇', [':person_bowing:', 4]),\n",
       " ('🔴', [':red_circle:', 4]),\n",
       " ('🌹', [':rose:', 4]),\n",
       " ('🖖', [':vulcan_salute:', 4]),\n",
       " ('🍻', [':clinking_beer_mugs:', 4]),\n",
       " ('😿', [':crying_cat:', 4]),\n",
       " ('🖕', [':middle_finger:', 3]),\n",
       " ('🥊', [':boxing_glove:', 3]),\n",
       " ('😚', [':kissing_face_with_closed_eyes:', 3]),\n",
       " ('🧘', [':person_in_lotus_position:', 3]),\n",
       " ('🙆', [':person_gesturing_OK:', 3]),\n",
       " ('📝', [':memo:', 3]),\n",
       " ('✍', [':writing_hand:', 3]),\n",
       " ('❌', [':cross_mark:', 3]),\n",
       " ('🐘', [':elephant:', 3]),\n",
       " ('📖', [':open_book:', 3]),\n",
       " ('📸', [':camera_with_flash:', 3]),\n",
       " ('🎭', [':performing_arts:', 3]),\n",
       " ('🔲', [':black_square_button:', 3]),\n",
       " ('🌼', [':blossom:', 3]),\n",
       " ('🕊', [':dove:', 3]),\n",
       " ('🤢', [':nauseated_face:', 3]),\n",
       " ('😙', [':kissing_face_with_smiling_eyes:', 3]),\n",
       " ('🚶', [':person_walking:', 3]),\n",
       " ('🧀', [':cheese_wedge:', 3]),\n",
       " ('®', [':registered:', 3]),\n",
       " ('🌕', [':full_moon:', 3]),\n",
       " ('🏆', [':trophy:', 3]),\n",
       " ('🌧', [':cloud_with_rain:', 3]),\n",
       " ('📹', [':video_camera:', 3]),\n",
       " ('🌊', [':water_wave:', 3]),\n",
       " ('🌎', [':globe_showing_Americas:', 3]),\n",
       " ('♌', [':Leo:', 3]),\n",
       " ('😮', [':face_with_open_mouth:', 3]),\n",
       " ('👼', [':baby_angel:', 3]),\n",
       " ('📺', [':television:', 3]),\n",
       " ('🦠', [':microbe:', 3]),\n",
       " ('💩', [':pile_of_poo:', 3]),\n",
       " ('🕺', [':man_dancing:', 3]),\n",
       " ('🏴', [':black_flag:', 3]),\n",
       " ('©', [':copyright:', 3]),\n",
       " ('🌞', [':sun_with_face:', 3]),\n",
       " ('🏳', [':white_flag:', 3]),\n",
       " ('⭕', [':hollow_red_circle:', 3]),\n",
       " ('📣', [':megaphone:', 2]),\n",
       " ('🥋', [':martial_arts_uniform:', 2]),\n",
       " ('🎆', [':fireworks:', 2]),\n",
       " ('🍀', [':four_leaf_clover:', 2]),\n",
       " ('🏃', [':person_running:', 2]),\n",
       " ('🍕', [':pizza:', 2]),\n",
       " ('🐾', [':paw_prints:', 2]),\n",
       " ('📩', [':envelope_with_arrow:', 2]),\n",
       " ('🌍', [':globe_showing_Europe-Africa:', 2]),\n",
       " ('🎧', [':headphone:', 2]),\n",
       " ('❗', [':red_exclamation_mark:', 2]),\n",
       " ('😗', [':kissing_face:', 2]),\n",
       " ('☑', [':check_box_with_check:', 2]),\n",
       " ('🐶', [':dog_face:', 2]),\n",
       " ('👑', [':crown:', 2]),\n",
       " ('😋', [':face_savoring_food:', 2]),\n",
       " ('🍒', [':cherries:', 2]),\n",
       " ('🐻', [':bear:', 2]),\n",
       " ('👴', [':old_man:', 2]),\n",
       " ('🧖', [':person_in_steamy_room:', 2]),\n",
       " ('👨', [':man:', 2]),\n",
       " ('👹', [':ogre:', 2]),\n",
       " ('🤥', [':lying_face:', 2]),\n",
       " ('💉', [':syringe:', 2]),\n",
       " ('🎪', [':circus_tent:', 2]),\n",
       " ('✝', [':latin_cross:', 2]),\n",
       " ('😧', [':anguished_face:', 2]),\n",
       " ('🥳', [':partying_face:', 2]),\n",
       " ('🍳', [':cooking:', 2]),\n",
       " ('🎤', [':microphone:', 2]),\n",
       " ('🖐', [':hand_with_fingers_splayed:', 2]),\n",
       " ('🔪', [':kitchen_knife:', 2]),\n",
       " ('👽', [':alien:', 2]),\n",
       " ('🧢', [':billed_cap:', 2]),\n",
       " ('☁', [':cloud:', 2]),\n",
       " ('🤲', [':palms_up_together:', 2]),\n",
       " ('😻', [':smiling_cat_with_heart-eyes:', 2]),\n",
       " ('☄', [':comet:', 2]),\n",
       " ('💐', [':bouquet:', 2]),\n",
       " ('💰', [':money_bag:', 2]),\n",
       " ('🥑', [':avocado:', 2]),\n",
       " ('🏖', [':beach_with_umbrella:', 2]),\n",
       " ('🗽', [':Statue_of_Liberty:', 2]),\n",
       " ('💬', [':speech_balloon:', 2]),\n",
       " ('🐖', [':pig:', 2]),\n",
       " ('📱', [':mobile_phone:', 2]),\n",
       " ('⬆', [':up_arrow:', 2]),\n",
       " ('👻', [':ghost:', 2]),\n",
       " ('🐡', [':blowfish:', 2]),\n",
       " ('🎮', [':video_game:', 2]),\n",
       " ('👾', [':alien_monster:', 2]),\n",
       " ('🍴', [':fork_and_knife:', 2]),\n",
       " ('🔫', [':water_pistol:', 2]),\n",
       " ('👸', [':princess:', 2]),\n",
       " ('☠', [':skull_and_crossbones:', 2]),\n",
       " ('🎙', [':studio_microphone:', 2]),\n",
       " ('🎨', [':artist_palette:', 2]),\n",
       " ('🍾', [':bottle_with_popping_cork:', 2]),\n",
       " ('🧔', [':person_beard:', 2]),\n",
       " ('🕸', [':spider_web:', 2]),\n",
       " ('☔', [':umbrella_with_rain_drops:', 2]),\n",
       " ('🔜', [':SOON_arrow:', 2]),\n",
       " ('⛈', [':cloud_with_lightning_and_rain:', 2]),\n",
       " ('🍟', [':french_fries:', 2]),\n",
       " ('🐄', [':cow:', 1]),\n",
       " ('🥛', [':glass_of_milk:', 1]),\n",
       " ('🍅', [':tomato:', 1]),\n",
       " ('🐸', [':frog:', 1]),\n",
       " ('🎇', [':sparkler:', 1]),\n",
       " ('🙍', [':person_frowning:', 1]),\n",
       " ('🥂', [':clinking_glasses:', 1]),\n",
       " ('🍌', [':banana:', 1]),\n",
       " ('🌬', [':wind_face:', 1]),\n",
       " ('🐐', [':goat:', 1]),\n",
       " ('😾', [':pouting_cat:', 1]),\n",
       " ('🏀', [':basketball:', 1]),\n",
       " ('🚬', [':cigarette:', 1]),\n",
       " ('🗨', [':left_speech_bubble:', 1]),\n",
       " ('🐿', [':chipmunk:', 1]),\n",
       " ('🌴', [':palm_tree:', 1]),\n",
       " ('🌷', [':tulip:', 1]),\n",
       " ('🔄', [':counterclockwise_arrows_button:', 1]),\n",
       " ('🤐', [':zipper-mouth_face:', 1]),\n",
       " ('🚪', [':door:', 1]),\n",
       " ('🧿', [':nazar_amulet:', 1]),\n",
       " ('🍊', [':tangerine:', 1]),\n",
       " ('🤴', [':prince:', 1]),\n",
       " ('🥣', [':bowl_with_spoon:', 1]),\n",
       " ('🐟', [':fish:', 1]),\n",
       " ('🖋', [':fountain_pen:', 1]),\n",
       " ('🐈', [':cat:', 1]),\n",
       " ('🐱', [':cat_face:', 1]),\n",
       " ('🗡', [':dagger:', 1]),\n",
       " ('🚹', [':men’s_room:', 1]),\n",
       " ('🚺', [':women’s_room:', 1]),\n",
       " ('🌩', [':cloud_with_lightning:', 1]),\n",
       " ('🐣', [':hatching_chick:', 1]),\n",
       " ('👄', [':mouth:', 1]),\n",
       " ('👃', [':nose:', 1]),\n",
       " ('🎥', [':movie_camera:', 1]),\n",
       " ('🎡', [':ferris_wheel:', 1]),\n",
       " ('🤜', [':right-facing_fist:', 1]),\n",
       " ('😲', [':astonished_face:', 1]),\n",
       " ('🕕', [':six_o’clock:', 1]),\n",
       " ('🔐', [':locked_with_key:', 1]),\n",
       " ('🤤', [':drooling_face:', 1]),\n",
       " ('👣', [':footprints:', 1]),\n",
       " ('👂', [':ear:', 1]),\n",
       " ('🌐', [':globe_with_meridians:', 1]),\n",
       " ('🎸', [':guitar:', 1]),\n",
       " ('💨', [':dashing_away:', 1]),\n",
       " ('💴', [':yen_banknote:', 1]),\n",
       " ('🚗', [':automobile:', 1]),\n",
       " ('🌨', [':cloud_with_snow:', 1]),\n",
       " ('🕯', [':candle:', 1]),\n",
       " ('🦄', [':unicorn:', 1]),\n",
       " ('◼', [':black_medium_square:', 1]),\n",
       " ('🐺', [':wolf:', 1]),\n",
       " ('⚕', [':medical_symbol:', 1]),\n",
       " ('🧤', [':gloves:', 1]),\n",
       " ('🌙', [':crescent_moon:', 1]),\n",
       " ('🏁', [':chequered_flag:', 1]),\n",
       " ('🌑', [':new_moon:', 1]),\n",
       " ('🛁', [':bathtub:', 1]),\n",
       " ('🎓', [':graduation_cap:', 1]),\n",
       " ('🥜', [':peanuts:', 1]),\n",
       " ('▶', [':play_button:', 1]),\n",
       " ('☂', [':umbrella:', 1]),\n",
       " ('🧻', [':roll_of_paper:', 1]),\n",
       " ('🎯', [':bullseye:', 1]),\n",
       " ('🌵', [':cactus:', 1]),\n",
       " ('🌪', [':tornado:', 1]),\n",
       " ('💍', [':ring:', 1]),\n",
       " ('👈', [':backhand_index_pointing_left:', 1]),\n",
       " ('🛡', [':shield:', 1]),\n",
       " ('🐠', [':tropical_fish:', 1]),\n",
       " ('🅾', [':O_button_(blood_type):', 1]),\n",
       " ('Ⓜ', [':circled_M:', 1]),\n",
       " ('🅱', [':B_button_(blood_type):', 1]),\n",
       " ('📉', [':chart_decreasing:', 1]),\n",
       " ('👰', [':person_with_veil:', 1]),\n",
       " ('💌', [':love_letter:', 1]),\n",
       " ('📲', [':mobile_phone_with_arrow:', 1]),\n",
       " ('🌏', [':globe_showing_Asia-Australia:', 1]),\n",
       " ('🐰', [':rabbit_face:', 1]),\n",
       " ('🍽', [':fork_and_knife_with_plate:', 1]),\n",
       " ('📚', [':books:', 1]),\n",
       " ('📢', [':loudspeaker:', 1]),\n",
       " ('🧜', [':merperson:', 1]),\n",
       " ('🧟', [':zombie:', 1]),\n",
       " ('⚰', [':coffin:', 1]),\n",
       " ('🆘', [':SOS_button:', 1]),\n",
       " ('♾', [':infinity:', 1]),\n",
       " ('🎫', [':ticket:', 1]),\n",
       " ('🛑', [':stop_sign:', 1]),\n",
       " ('🥄', [':spoon:', 1]),\n",
       " ('👫', [':woman_and_man_holding_hands:', 1]),\n",
       " ('👟', [':running_shoe:', 1]),\n",
       " ('🗑', [':wastebasket:', 1]),\n",
       " ('✒', [':black_nib:', 1]),\n",
       " ('🚌', [':bus:', 1]),\n",
       " ('🚆', [':train:', 1]),\n",
       " ('🚇', [':metro:', 1]),\n",
       " ('🚘', [':oncoming_automobile:', 1]),\n",
       " ('⛅', [':sun_behind_cloud:', 1]),\n",
       " ('🔑', [':key:', 1]),\n",
       " ('💧', [':droplet:', 1]),\n",
       " ('💎', [':gem_stone:', 1]),\n",
       " ('🍏', [':green_apple:', 1]),\n",
       " ('🥕', [':carrot:', 1]),\n",
       " ('🍓', [':strawberry:', 1]),\n",
       " ('👆', [':backhand_index_pointing_up:', 1]),\n",
       " ('✂', [':scissors:', 1]),\n",
       " ('🌝', [':full_moon_face:', 1]),\n",
       " ('🦇', [':bat:', 1]),\n",
       " ('🍎', [':red_apple:', 1]),\n",
       " ('👺', [':goblin:', 1]),\n",
       " ('✏', [':pencil:', 1]),\n",
       " ('🛫', [':airplane_departure:', 1]),\n",
       " ('🌺', [':hibiscus:', 1]),\n",
       " ('🔵', [':blue_circle:', 1]),\n",
       " ('🌀', [':cyclone:', 1]),\n",
       " ('🏏', [':cricket_game:', 1])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes = df.copy()\n",
    "emoji_map = {}\n",
    "\n",
    "def get_emoji_map(tweet, map):\n",
    "    if type(tweet) == 'float64':\n",
    "        print(tweet)\n",
    "    for char in tweet:\n",
    "        if emoji.is_emoji(char):\n",
    "            if char not in map.keys():\n",
    "                map[char] = [emoji.demojize(char), 1]\n",
    "            else:\n",
    "                map[char][1] += 1\n",
    "                \n",
    "df_attributes['tweet'].apply(get_emoji_map, map=emoji_map)\n",
    "sorted_emoji_map = sorted(emoji_map.items(), key=lambda x:x[1][1], reverse=True)\n",
    "sorted_emoji_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d315c6a5-4b91-4ea1-800a-07970380ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I exract positive and negative emojis using the analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "emoji_df = pd.DataFrame(columns=['emoji', 'emoji_unicode', 'emoji_count', 'pos_score', 'neg_score', 'neu_score', 'compound_score'])\n",
    "\n",
    "for key, val in emoji_map.items():\n",
    "    emoji_df.loc[len(emoji_df.index)] = [key, val[0], val[1], analyzer.polarity_scores(key)['pos'], analyzer.polarity_scores(key)['neg'], analyzer.polarity_scores(key)['neu'], analyzer.polarity_scores(key)['compound']]\n",
    "\n",
    "pos_df = emoji_df[emoji_df['compound_score'] > 0.27]\n",
    "neg_df = emoji_df[emoji_df['compound_score'] < -0.27]\n",
    "\n",
    "pos_emojis = pos_df['emoji_unicode'].tolist()\n",
    "neg_emojis = neg_df['emoji_unicode'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae32fe3-3dbf-4d03-b3f4-e6b0274e86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url_link(tweet):\n",
    "    sentence = tweet.split(' ')\n",
    "    for word in sentence:\n",
    "        if word.startswith('https:') or word.startswith('http:'): \n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def check_pos_emoji(tweet):\n",
    "    for char in tweet:\n",
    "        if emoji.is_emoji(char) and char in pos_emojis:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def check_neg_emoji(tweet):\n",
    "    for char in tweet:\n",
    "        if emoji.is_emoji(char) and char in neg_emojis:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def get_tweet_length(tweet):\n",
    "    sentence = tweet.split(' ')\n",
    "    res = \" \"\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word.startswith('https:') or word.startswith('http:') or word.startswith('pic.twitter.com'):\n",
    "            sentence.remove(word)\n",
    "    return len(res.join(sentence))\n",
    "\n",
    "def get_profanity_words(tweet):\n",
    "    cleaned_tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    sentence = cleaned_tweet.split(' ') \n",
    "    profanity_wordlist = np.loadtxt('../data/profanity_wordlist.txt', dtype='str')\n",
    "    count = 0\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word.lower() in profanity_wordlist:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e368411-a0ba-4e29-bba5-756adc9c47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been trying to figure out why my depression is so damn hard to shake today. I knew something was going on. - 0\n",
      "\n",
      "url link: 0\n",
      "positive emoji: 0\n",
      "negative emoji: 0\n",
      "tweet length: 111\n",
      "profanity word: 1\n"
     ]
    }
   ],
   "source": [
    "tweet_num = 22913\n",
    "\n",
    "tweet = df_attributes['tweet'][tweet_num]\n",
    "vader_score = df_attributes['vader_sentiment_label'][tweet_num]\n",
    "\n",
    "print(f\"{tweet} - {vader_score}\\n\")\n",
    "print(f\"url link: {check_url_link(tweet)}\")\n",
    "print(f\"positive emoji: {check_pos_emoji(tweet)}\")\n",
    "print(f\"negative emoji: {check_neg_emoji(tweet)}\")\n",
    "print(f\"tweet length: {get_tweet_length(tweet)}\")\n",
    "print(f\"profanity word: {get_profanity_words(tweet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582ba9d1-a8fd-4060-a7b5-ca55926b2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attributes['tweet_length'] = df_attributes['tweet'].apply(get_tweet_length)\n",
    "df_attributes['url_link'] = df_attributes['tweet'].apply(check_url_link)\n",
    "df_attributes['pos_emoji'] = df_attributes['tweet'].apply(check_pos_emoji)\n",
    "df_attributes['neg_emoji'] = df_attributes['tweet'].apply(check_neg_emoji)\n",
    "df_attributes['profanity_word'] = df_attributes['tweet'].apply(get_profanity_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e63296-2be2-4bca-8d48-0af631f12407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_sentiment_label</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>url_link</th>\n",
       "      <th>pos_emoji</th>\n",
       "      <th>neg_emoji</th>\n",
       "      <th>profanity_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.2699</td>\n",
       "      <td>Wow, my dad yday: “you don’t take those stupid...</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.5995</td>\n",
       "      <td>what part of this was really harmfult of a lot...</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>one of the ways I got through my #depression i...</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.8643</td>\n",
       "      <td>see i wanna do one of them but they all say th...</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>IS IT clinical depression or is it the palpabl...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>CBD for depression? Nature works in mysterious...</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22959</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>Depression is real</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22960</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.5060</td>\n",
       "      <td>Even though Tropical Depression Barry did not ...</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22961</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.7906</td>\n",
       "      <td>https://medtally.com/post/cluster-analysis-wi...</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22962</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.7783</td>\n",
       "      <td>New clinical trial for #depression: Task Shift...</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22963 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vader_sentiment_label  vader_score  \\\n",
       "0                          0      -0.2699   \n",
       "1                          0      -0.5995   \n",
       "2                          1       0.3382   \n",
       "3                          0      -0.8643   \n",
       "4                          0      -0.8316   \n",
       "...                      ...          ...   \n",
       "22958                      0      -0.8126   \n",
       "22959                      0      -0.5719   \n",
       "22960                      0      -0.5060   \n",
       "22961                      0      -0.7906   \n",
       "22962                      0      -0.7783   \n",
       "\n",
       "                                                   tweet  tweet_length  \\\n",
       "0      Wow, my dad yday: “you don’t take those stupid...           278   \n",
       "1      what part of this was really harmfult of a lot...           274   \n",
       "2      one of the ways I got through my #depression i...           208   \n",
       "3      see i wanna do one of them but they all say th...           114   \n",
       "4      IS IT clinical depression or is it the palpabl...            78   \n",
       "...                                                  ...           ...   \n",
       "22958  CBD for depression? Nature works in mysterious...           116   \n",
       "22959                                 Depression is real            18   \n",
       "22960  Even though Tropical Depression Barry did not ...           245   \n",
       "22961   https://medtally.com/post/cluster-analysis-wi...            83   \n",
       "22962  New clinical trial for #depression: Task Shift...           127   \n",
       "\n",
       "       url_link  pos_emoji  neg_emoji  profanity_word  \n",
       "0             0          0          0               0  \n",
       "1             0          0          0               0  \n",
       "2             0          0          0               0  \n",
       "3             0          0          0               0  \n",
       "4             0          0          0               0  \n",
       "...         ...        ...        ...             ...  \n",
       "22958         1          0          0               0  \n",
       "22959         0          0          0               0  \n",
       "22960         1          0          0               0  \n",
       "22961         1          0          0               0  \n",
       "22962         1          0          0               0  \n",
       "\n",
       "[22963 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529b1ed-b0bc-4065-bb9e-48de583e22b7",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Data should be processed in a way that it can be vectorized for tokenization.\n",
    "\n",
    "(Note: At this point, not so sure about removing hashtags. Maybe will delete later)\n",
    "\n",
    "- All tweets converted into lowercase.\n",
    "- URL(s) removed from tweets. Such as, \"https...., pic.twitter.com/...\"\n",
    "- All contractions are expanded.\n",
    "- Accented chars are converted into original forms. Such as, \"á\": \"a\"\n",
    "- All emojis, mentions and digits are removed.\n",
    "- All punctuation marks and special characters (i.e. £, $) are removed.\n",
    "- All stopwords are removed.\n",
    "- Finally, stemming is applied for a more robust data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22ac738-6268-4d3c-a184-11d24b94959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_attributes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c606bf02-8c79-4b8b-8ae5-74a10302b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(tweet):\n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "412fd8b6-25cc-4598-8356-40e6fc22cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove url links such as, 'https://...', 'http://...', or 'pic.twitter...'\n",
    "def remove_url(tweet):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r'pic\\.twitter\\.com\\S+', '', tweet)\n",
    "    tweet = re.sub(r'www.+', '', tweet)\n",
    "    tweet = tweet.replace(u'\\xa0', u' ')\n",
    "    \n",
    "    return tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ee7195-d03e-46f7-b611-0201713f03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary contains contractions and their expanded forms\n",
    "contractions_dict = {\n",
    "  \"brb\": \"be right back\",\n",
    "  \"btw\": \"by the way\",\n",
    "  \"cant\": \"can not\",\n",
    "  \"dont\": \"do not\",\n",
    "  \"doesnt\": \"doesn ot\",\n",
    "  \"didnt\": \"did not\",\n",
    "  \"hasnt\": \"has not\",\n",
    "  \"havent\": \"have not\",\n",
    "  \"heres\": \"here is\",\n",
    "  \"howd\": \"how did\",\n",
    "  \"howve\": \"how have\",  \n",
    "  \"hows\": \"how is\",\n",
    "  \"id\": \"i would\",\n",
    "  \"ive\": \"i have\",\n",
    "  \"isnt\": \"is not\",\n",
    "  \"itd\": \"it would\",\n",
    "  \"itll\": \"it will\",\n",
    "  \"its\": \"it iss\",\n",
    "  \"kys\": \"kill yourself\",  \n",
    "  \"lets\": \"let us\", \n",
    "  \"ngl\": \"not gonna lie\",\n",
    "  \"omg\": \"oh my god\",\n",
    "  \"omfg\": \"oh my fucking god\",  \n",
    "  \"shes\": \"she is\",\n",
    "  \"stfu\": \"shut the fuck up\",  \n",
    "  \"thats\": \"that is\",\n",
    "  \"theres\": \"there is\",\n",
    "  \"theyd\": \"they would\",\n",
    "  \"theyll\": \"they will\",\n",
    "  \"theyre\": \"they are\",\n",
    "  \"theyve\": \"they have\",\n",
    "  \"thisll\": \"this will\",  \n",
    "  \"uve\": \"you have\",  \n",
    "  \"wasnt\": \"was not\",\n",
    "  \"wed\": \"we would\",\n",
    "  \"werent\": \"were not\",\n",
    "  \"whatll\": \"what will\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"whats\": \"what is\",\n",
    "  \"whatve\": \"what have\",\n",
    "  \"whens\": \"when is\",\n",
    "  \"whered\": \"where would\",\n",
    "  \"wheres\": \"where is\",\n",
    "  \"whereve\": \"where have\",\n",
    "  \"wholl\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"whos\": \"who is\",\n",
    "  \"whove\": \"who have\",\n",
    "  \"whys\": \"why is\",\n",
    "  \"whyve\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"wont\": \"will not\",\n",
    "  \"wouldve\": \"would have\",\n",
    "  \"wouldnt\": \"would not\",\n",
    "  \"yall\": \"you all\",\n",
    "  \"yalls\": \"you alls\",\n",
    "  \"youd\": \"you would\",\n",
    "  \"youll\": \"you will\",\n",
    "  \"youllve\": \"you will have\",\n",
    "  \"youre\": \"you are\",\n",
    "  \"youve\": \"you have\",\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"here's\": \"here is\", \n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how've\": \"how have\",  \n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"i'd\": \"i would\",\n",
    "  \"i'd've\": \"i would have\",\n",
    "  \"i'll\": \"i will\",\n",
    "  \"i'll've\": \"i will have\",\n",
    "  \"i'm\": \"i am\",\n",
    "  \"i've\": \"i have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"seen't\": \"see not\",  \n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that'll\": \"that will\", \n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"this'll\": \"this will\",  \n",
    "  \"to've\": \"to have\",\n",
    "  \"u've\": \"you have\",  \n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"ya'll\": \"you all\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"yday\": \"yesterday\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you will\",\n",
    "  \"you'll've\": \"you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n",
    "\"\"\"\n",
    "    create a regular expression pattern using 'contractions_dict'\n",
    "    this pattern is used to identify contractions in the given input string\n",
    "\"\"\"\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "\"\"\"\n",
    "    replaces all occurrences of contractions in the input string with their expanded forms\n",
    "    'replace' function is used as the replacement function, and it's applied to each match found by the regular expression\n",
    "\"\"\"\n",
    "def expand_contractions(tweet, contractions_dict=contractions_dict):\n",
    "    # takes a 'match' object and returns corresponded expansion form\n",
    "    tweet = tweet.replace(\"’\", \"'\")\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "029963b7-63d5-4346-ab95-3203f893c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    convert accent characters into standard ASCII characters\n",
    "    Such as: résumé, café, prótest, divorcé => resume, cafe, protest, divorce\n",
    "\"\"\"\n",
    "def convert_accented_chars(tweet):\n",
    "    return unicodedata.normalize('NFKD', tweet).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43ebdce0-ba61-4c98-a2b3-1d607e43cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(tweet):\n",
    "    return ''.join(char for char in tweet if not emoji.is_emoji(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c88661-7cba-4339-bc2e-296bdd2776c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove mentions (and tags ?)\n",
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\S*', '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f795c2-f59e-47be-8850-bfa506569b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove digits\n",
    "def remove_digits(tweet):\n",
    "    return ''.join(char for char in tweet if not char.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1824d57e-4806-481d-b806-ab146e9d55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(tweet):\n",
    "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pattern, '', tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc087b83-14b6-4ff9-9b9c-7607cf60d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(tweet):\n",
    "    return ''.join([char for char in tweet if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f16b72-3353-42ea-9c95-d9e208f70743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tweet):\n",
    "    word_tokens = nltk.word_tokenize(tweet) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stopword_list]\n",
    "    tweet = ' '.join(filtered_sentence)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10c4da8a-fdef-4190-9f38-5bf05c0989ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['tweet'] = df_clean['tweet'].apply(to_lowercase)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_url)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(expand_contractions)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(convert_accented_chars)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_emojis)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_mentions)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_digits)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_special_characters)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_punctuation)\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(remove_stopwords)\n",
    "\n",
    "df_clean.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bbefda7-1f68-4594-bf0c-bb67f880cbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22963 entries, 0 to 22962\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   vader_sentiment_label  22963 non-null  int64  \n",
      " 1   vader_score            22963 non-null  float64\n",
      " 2   tweet                  22963 non-null  object \n",
      " 3   tweet_length           22963 non-null  int64  \n",
      " 4   url_link               22963 non-null  int64  \n",
      " 5   pos_emoji              22963 non-null  int64  \n",
      " 6   neg_emoji              22963 non-null  int64  \n",
      " 7   profanity_word         22963 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790f405-6a6d-49cc-b21f-96790af3aba3",
   "metadata": {},
   "source": [
    "### Some tweets remained as an empty string after unnecessary parts were removed.\n",
    "Such as:\n",
    "    \"💜💜💜 @NewYorkTimes\" => \" \"\n",
    "\n",
    "These rows must be removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5073aa68-a59e-481c-ba2d-41694a2b3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_sentiment_label</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>url_link</th>\n",
       "      <th>pos_emoji</th>\n",
       "      <th>neg_emoji</th>\n",
       "      <th>profanity_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7845</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6369</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22650</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22708</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22731</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22779</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4939</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22820</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9274</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vader_sentiment_label  vader_score tweet  tweet_length  url_link  \\\n",
       "1281                       0       0.0000                   2         0   \n",
       "1447                       1       0.7845                   7         0   \n",
       "1450                       0       0.0000                   0         0   \n",
       "1723                       1       0.6369                   3         0   \n",
       "1732                       0       0.0000                 132         0   \n",
       "...                      ...          ...   ...           ...       ...   \n",
       "22650                      0       0.0000                   0         0   \n",
       "22708                      0       0.0000                   0         0   \n",
       "22731                      0       0.0000                   0         0   \n",
       "22779                      1       0.4939                   2         0   \n",
       "22820                      1       0.9274                   3         0   \n",
       "\n",
       "       pos_emoji  neg_emoji  profanity_word  \n",
       "1281           0          0               0  \n",
       "1447           0          0               0  \n",
       "1450           0          0               0  \n",
       "1723           0          0               0  \n",
       "1732           0          0               0  \n",
       "...          ...        ...             ...  \n",
       "22650          0          0               0  \n",
       "22708          0          0               0  \n",
       "22731          0          0               0  \n",
       "22779          0          0               0  \n",
       "22820          0          0               0  \n",
       "\n",
       "[133 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['tweet'].str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7e9530-1320-434a-80e8-744b458a8093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22830"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove row...s where 'tweet' column is empty\n",
    "df_clean = df_clean[df_clean['tweet'].str.len() > 0]\n",
    "\n",
    "len(df_clean.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e2ecc-89cd-4504-911d-9d5aba117661",
   "metadata": {},
   "source": [
    "After cleaning the text, the text should be processed with Stemmer before tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b47c2e56-e2f4-4bea-abb9-08034e735f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_stem(tweet, stemmer=stemmer):\n",
    "    return ' '.join([stemmer.stem(word) for word in tweet.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f273a3a-0b9f-4c71-a45b-05cd92a33700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['tweet'] = df_clean['tweet'].apply(get_stem) \n",
    "df_clean.to_csv('../data/preprocessed_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
