{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b4da41-23c8-4f0b-a998-2f13d22b1b94",
   "metadata": {
    "id": "c1b4da41-23c8-4f0b-a998-2f13d22b1b94"
   },
   "source": [
    "### `Tokenization and Embedding Extraction with BERT`\n",
    "\n",
    "The text is cleaned and should be tokenized in a way that the embeddings can be extracted for later training.\n",
    "\n",
    "Let's install required modules for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861f725-9d21-4b77-aa82-9bd50a2c4778",
   "metadata": {
    "id": "c861f725-9d21-4b77-aa82-9bd50a2c4778"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification, WEIGHTS_NAME, CONFIG_NAME\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import pad_sequences\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ec295-33ba-45a9-a371-ba3a62adf5d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "364ec295-33ba-45a9-a371-ba3a62adf5d4",
    "outputId": "14d3b189-317a-44a9-b92a-b76e0118bc79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22830, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_tweets = pd.read_csv('../data/preprocessed_tweets.csv')\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e3dc2-d89d-46ee-82f5-90cee6003da9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "e52e3dc2-d89d-46ee-82f5-90cee6003da9",
    "outputId": "3e7afb29-5ad6-4ac9-f38f-1c0afaecb2ee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_tweets\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"vader_sentiment_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vader_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4752309315830918,\n        \"min\": -0.8131,\n        \"max\": 0.8481,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.4329,\n          -0.34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"depress hour yeah playlist oathkeep mickey\",\n          \"ima buy ticket dr next week christma need break fr think ima get huge depress stay\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76,\n        \"min\": 12,\n        \"max\": 244,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          78,\n          127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url_link\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_emoji\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neg_emoji\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"profanity_word\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f6e20840-b42d-4291-bc4e-9857297b3e5f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_sentiment_label</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>url_link</th>\n",
       "      <th>pos_emoji</th>\n",
       "      <th>neg_emoji</th>\n",
       "      <th>profanity_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.8056</td>\n",
       "      <td>bipolar expedit film reveal manic high addicti...</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18520</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>ima buy ticket dr next week christma need brea...</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>saw psychiatrist morn talk ok thing late depre...</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>illustr mum ki would book give child view pare...</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>final hit post graduat depress</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9816</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>find someon love flow ri haver enough keep flo...</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.8131</td>\n",
       "      <td>one way battl depress gi big pharma mi woulddl...</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22238</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.6114</td>\n",
       "      <td>depress</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.4329</td>\n",
       "      <td>depress hour yeah playlist oathkeep mickey</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>use cbd work wonder anxieti depress would reco...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6e20840-b42d-4291-bc4e-9857297b3e5f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f6e20840-b42d-4291-bc4e-9857297b3e5f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f6e20840-b42d-4291-bc4e-9857297b3e5f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-21ae3aea-5a20-4c72-b364-55cec035347b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21ae3aea-5a20-4c72-b364-55cec035347b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-21ae3aea-5a20-4c72-b364-55cec035347b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       vader_sentiment_label  vader_score  \\\n",
       "8054                       0      -0.8056   \n",
       "18520                      0      -0.3400   \n",
       "1383                       0      -0.6486   \n",
       "5654                       0      -0.4767   \n",
       "7378                       0      -0.5719   \n",
       "9816                       1       0.8481   \n",
       "3310                       0      -0.8131   \n",
       "22238                      0      -0.6114   \n",
       "3823                       0      -0.4329   \n",
       "11579                      0      -0.4404   \n",
       "\n",
       "                                                   tweet  tweet_length  \\\n",
       "8054   bipolar expedit film reveal manic high addicti...           226   \n",
       "18520  ima buy ticket dr next week christma need brea...           127   \n",
       "1383   saw psychiatrist morn talk ok thing late depre...           130   \n",
       "5654   illustr mum ki would book give child view pare...           244   \n",
       "7378                      final hit post graduat depress            48   \n",
       "9816   find someon love flow ri haver enough keep flo...           201   \n",
       "3310   one way battl depress gi big pharma mi woulddl...           116   \n",
       "22238                                            depress            12   \n",
       "3823          depress hour yeah playlist oathkeep mickey            78   \n",
       "11579  use cbd work wonder anxieti depress would reco...            81   \n",
       "\n",
       "       url_link  pos_emoji  neg_emoji  profanity_word  \n",
       "8054          1          0          0               0  \n",
       "18520         0          0          0               0  \n",
       "1383          0          0          0               1  \n",
       "5654          0          0          0               0  \n",
       "7378          0          0          0               0  \n",
       "9816          1          0          0               0  \n",
       "3310          0          0          0               0  \n",
       "22238         1          0          0               0  \n",
       "3823          1          0          0               0  \n",
       "11579         0          0          0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = df_tweets.drop(['Unnamed: 0'], axis=1)\n",
    "df_tweets.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc45edb-ba18-472c-a1f2-9d50ce64d0ff",
   "metadata": {
    "id": "adc45edb-ba18-472c-a1f2-9d50ce64d0ff"
   },
   "source": [
    "### Inputs\n",
    "**BERT** requires specifically formatted inputs. For each tokenized input sentence, we need to create:\n",
    "\n",
    "- **input ids**: a sequence of integers identifying each input token to its index number in the BERT tokenizer vocabulary\n",
    "- **segment mask**: (optional) a sequence of 1s and 0s used to identify whether the input is one sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. For two sentence inputs, there is a 0 for each token of the first sentence, followed by a 1 for each token of the second sentence. Will not be used in this project.\n",
    "- **attention mask**: (optional) a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens (we'll detail this in the next paragraph)\n",
    "- **labels**: a single value of 1 or 0. In our task 1 means \"grammatical\" and 0 means \"ungrammatical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0ebd8-9985-41dd-874a-6f88c5dfdf6e",
   "metadata": {
    "id": "10b0ebd8-9985-41dd-874a-6f88c5dfdf6e"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "PADDING = 'post'\n",
    "TRUNCATING = 'post'\n",
    "TRAINING_SPLIT = .75\n",
    "DTYPE = 'long'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f98292-4116-4cf9-a6a4-d859672fcd93",
   "metadata": {
    "id": "51f98292-4116-4cf9-a6a4-d859672fcd93"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea3bcc-a2b5-4451-a69a-a9988426035f",
   "metadata": {
    "id": "31ea3bcc-a2b5-4451-a69a-a9988426035f"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Returns tokens of the tweet, and tensors of the tokens and segment ids\n",
    "def tokenization(tweets, maxlen=MAX_LEN, dtype=DTYPE, truncating=TRUNCATING, padding=PADDING, tokenizer=tokenizer):\n",
    "    tweets = [\"[CLS] \" + tweet + \" [SEP]\" for tweet in tweets]\n",
    "    tokenized_texts = [tokenizer.tokenize(tweet) for tweet in tweets]\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(text) for text in tokenized_texts]\n",
    "\n",
    "    # Pad our input tokens\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=dtype, truncating=truncating, padding=padding)\n",
    "\n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "\n",
    "    for seq in input_ids:\n",
    "      seq_mask = [float(i>0) for i in seq]\n",
    "      attention_masks.append(seq_mask)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    # tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    # segments_tensor = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_texts, input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b2bb0-9e78-4464-8837-db9da2b925fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "a96b2bb0-9e78-4464-8837-db9da2b925fa",
    "outputId": "891d2890-c842-4631-f5aa-028c275e8769"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'wow dad yesterday take stupi would depress drug anymor though absolut worst thing never need great famili supporti mom sister stanc similar way'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tweets and labels lists\n",
    "tweets = df_tweets.tweet.values\n",
    "labels = df_tweets.vader_sentiment_label.values\n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813d163-df7c-41a1-8794-f17e4331907e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9813d163-df7c-41a1-8794-f17e4331907e",
    "outputId": "bbe5cadb-dc6f-40aa-ff12-3d3961bb5b90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS]',\n",
       "  'wow',\n",
       "  'dad',\n",
       "  'yesterday',\n",
       "  'take',\n",
       "  'stu',\n",
       "  '##pi',\n",
       "  'would',\n",
       "  'de',\n",
       "  '##press',\n",
       "  'drug',\n",
       "  'any',\n",
       "  '##mo',\n",
       "  '##r',\n",
       "  'though',\n",
       "  'abs',\n",
       "  '##ol',\n",
       "  '##ut',\n",
       "  'worst',\n",
       "  'thing',\n",
       "  'never',\n",
       "  'need',\n",
       "  'great',\n",
       "  'fa',\n",
       "  '##mi',\n",
       "  '##li',\n",
       "  'support',\n",
       "  '##i',\n",
       "  'mom',\n",
       "  'sister',\n",
       "  'stan',\n",
       "  '##c',\n",
       "  'similar',\n",
       "  'way',\n",
       "  '[SEP]'],\n",
       " 101,\n",
       " [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts, input_ids, attention_masks = tokenization(tweets)\n",
    "tokenized_texts[0], input_ids[0][0], attention_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88xFobF70t6C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88xFobF70t6C",
    "outputId": "686eb2a2-ff93-49f1-a872-a079e1dcce04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 10166,  3611,  7483,  2202, 24646,  8197,  2052,  2139,\n",
       "       20110,  4319,  2151,  5302,  2099,  2295, 14689,  4747,  4904,\n",
       "        5409,  2518,  2196,  2342,  2307,  6904,  4328,  3669,  2490,\n",
       "        2072,  3566,  2905,  9761,  2278,  2714,  2126,   102,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a847af-d266-49a8-8900-cd9daaa20360",
   "metadata": {
    "id": "05a847af-d266-49a8-8900-cd9daaa20360",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_val_split(input_ids, attention_masks, labels, training_split=TRAINING_SPLIT, batch_size=BATCH_SIZE):\n",
    "    # Use train_test_split to split our data into train and validation sets for training\n",
    "    train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
    "                                                                                        random_state=2018, train_size=training_split)\n",
    "    train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                                                                        random_state=2018, train_size=training_split)\n",
    "\n",
    "    # Convert all of our data into torch tensors, the required datatype for our model\n",
    "    train_inputs = torch.tensor(train_inputs)\n",
    "    validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "    train_masks = torch.tensor(train_masks)\n",
    "    validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "    # Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
    "    # with an iterator the entire dataset does not need to be loaded into memory\n",
    "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "    validation_sampler = SequentialSampler(validation_data)\n",
    "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece19373-0f5c-4f91-9622-e4feb3299d66",
   "metadata": {
    "id": "ece19373-0f5c-4f91-9622-e4feb3299d66"
   },
   "outputs": [],
   "source": [
    "train_dataloader, validation_dataloader = train_val_split(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f15f8-d552-464c-8f43-ed5c87d2beb5",
   "metadata": {
    "id": "eb2f15f8-d552-464c-8f43-ed5c87d2beb5"
   },
   "source": [
    "### Loading and Fine-Tuning BERT\n",
    "Now that our input data is properly formatted, it's time to fine tune the BERT model.\n",
    "\n",
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Because the pre-trained BERT layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking going on in the lower levels to accomodate our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124be261-37ba-4228-8dcb-6d5a57e3f730",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "124be261-37ba-4228-8dcb-6d5a57e3f730",
    "outputId": "f8c38296-4ad8-427a-bad7-f03c9d7dd11e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:10<00:00, 39757561.79B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b0d68-b29f-4826-887a-aba35a4e126d",
   "metadata": {
    "id": "2b2b0d68-b29f-4826-887a-aba35a4e126d"
   },
   "source": [
    "In order for torch to use the GPU, we need to identify and specify the GPU as\n",
    "the device. Later, in our training loop, we will load data onto the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cd977-f9e4-4ab8-9b36-64e374a3198e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "038cd977-f9e4-4ab8-9b36-64e374a3198e",
    "outputId": "9176137d-11c7-4eb8-f87f-604704366c60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62191801-c354-4452-b611-fb7ed6891937",
   "metadata": {
    "id": "62191801-c354-4452-b611-fb7ed6891937"
   },
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. At each pass we need to:\n",
    "\n",
    "Training loop:\n",
    "- Tell the model to compute gradients by setting the model in train mode\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "Evalution loop:\n",
    "- Tell the model not to compute gradients by setting the model in evaluation mode\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff34f4d-2225-453d-9a30-9971639cecb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dff34f4d-2225-453d-9a30-9971639cecb8",
    "outputId": "28f290d7-0c6e-4a42-867a-1e2787bdbca9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 4\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=LEARNING_RATE, warmup=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d586b-c9e5-499f-81af-1c607829a95b",
   "metadata": {
    "id": "6c7d586b-c9e5-499f-81af-1c607829a95b"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04a52f-d6d9-40ae-9596-05167b274abc",
   "metadata": {
    "id": "cd04a52f-d6d9-40ae-9596-05167b274abc"
   },
   "outputs": [],
   "source": [
    "def train_and_validation(train_dataloader, validation_dataloader, model, device, optimizer, epochs=EPOCHS):\n",
    "    # Store our loss and accuracy for plotting\n",
    "    train_loss_set = []\n",
    "\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "        # Training\n",
    "        # set our model to training mode (as opposed to evaluation mode)\n",
    "        model.train()\n",
    "\n",
    "        # tracking variables\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "        # train the data for one epoch\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            # unpack the inputs from dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            # clear out the gradients (by default they accumulate)\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            train_loss_set.append(loss.item())\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # update parameters and take a step using the computed gradient\n",
    "            optimizer.step()\n",
    "\n",
    "            # update tracking variables\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "        # Validation\n",
    "        # put model on evaluation mode to evaluate loss on the validation set\n",
    "        model.eval()\n",
    "\n",
    "        # tracking variables\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "        # evaluate the data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "            # add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            # unpack the inputs from dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            # telling the model not to compute or store gradients, saving memory and speed up validation\n",
    "            with torch.no_grad():\n",
    "                # forward pass, calculate logit predictions\n",
    "                logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "            # move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "\n",
    "    return train_loss_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b14e6c-5864-4c5c-9d89-023b8a84364d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80b14e6c-5864-4c5c-9d89-023b8a84364d",
    "outputId": "71eeb9bd-d7fe-4307-91d5-c58c350df5d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.361499218492588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 1/4 [07:31<22:35, 451.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8819250465549349\n",
      "Train loss: 0.2523930730826374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 2/4 [15:02<15:02, 451.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8921089385474861\n",
      "Train loss: 0.1693261123728007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 3/4 [22:33<07:30, 450.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8760474860335196\n",
      "Train loss: 0.10055865420970315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [30:03<00:00, 450.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8802374301675978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set = train_and_validation(train_dataloader, validation_dataloader, model, device, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gag57WbTzvbM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gag57WbTzvbM",
    "outputId": "e0bd4f91-ad9e-4088-9213-98b06de138fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/vocab.txt',)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./models/\"\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(output_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
